{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Plan:\n",
    " * 3-minute introduction to Neural Networks\n",
    "  * A sequence of operations\n",
    "  * or in details DAG\n",
    "  * Training: backpropagation\n",
    " * Convolution layers:\n",
    "  * Motivation:\n",
    "    * FFT?\n",
    "    * Filters?\n",
    "  * Params:\n",
    "    * Paddings\n",
    "    * spartial conv\n",
    "    * Layers\n",
    "    * formula\n",
    "    * kernel dims\n",
    "  * Convnets in CV:\n",
    "    * MNIST\n",
    "  * Convnets in NLP:\n",
    "    * character-level LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sieci Konwolucyjne w przetwarzaniu obrazów i tekstu\n",
    "\n",
    "### Tomasz Dwojak\n",
    "\n",
    "### 24 kwietnia 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wprowadzenie do NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " * podstawowe klocki: warstawy\n",
    " * układanie puzzli z klocków\n",
    " * wejście: $x \\in {R}^{n \\cdot m \\cdot k \\cdot l}$ - [tensor](https://stats.stackexchange.com/questions/198061/why-the-sudden-fascination-with-tensors):\n",
    "  * 0D tensor to skalar,\n",
    "  * 1D tensor to wektor,\n",
    "  * 2D tensor to macierz...\n",
    "  * 4D tensor to *macierz macierzy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def readMnist(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    return [get_img(i) for i in range(len(lbl))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def showImage(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "training = readMnist()\n",
    "print(training[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Warstwy (ang. *layers*):\n",
    " * liniowa: $ x \\leftarrow xW + b$\n",
    " * element-wise: $ x\\cdot W$\n",
    " * nieliniowe (f. aktywacji): np. $x \\leftarrow \\tanh(x)$, $x \\leftarrow \\sigma(x)$, $\\DeclareMathOperator{\\relu}{ReLU} x \\leftarrow \\relu(x)$\n",
    " * pooling:, np. max-pooling, ave-pooling\n",
    " * RNN: LSTM, GRU\n",
    " * Konwolucyjna: $x * W$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n",
    "\n",
    " * forward\n",
    " * computing loss function, e.g. MSE, CE\n",
    " * backward (back propagation)\n",
    " * update weights\n",
    " * repeat til some condition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, criterion, optimizer):\n",
    "    model.train()\n",
    "    for batch in batch_generator():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(batch[0]))\n",
    "        labels = Variable(torch.from_numpy(batch[1]))\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Images in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2748dc92e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImage(training[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000001111111111110000\n",
      "0000000011111111111111110000\n",
      "0000000111111111111111100000\n",
      "0000000111111111110000000000\n",
      "0000000011111110110000000000\n",
      "0000000001111100000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000011110000000000000\n",
      "0000000000001111110000000000\n",
      "0000000000000111111000000000\n",
      "0000000000000011111100000000\n",
      "0000000000000001111100000000\n",
      "0000000000000000011110000000\n",
      "0000000000000011111110000000\n",
      "0000000000001111111100000000\n",
      "0000000000111111111000000000\n",
      "0000000011111111110000000000\n",
      "0000001111111111000000000000\n",
      "0000111111111100000000000000\n",
      "0000111111110000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "example = ''\n",
    "print('\\n'.join([''.join([str(int(bool(col))) for col in row]) for row in training[0][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutions\n",
    "\n",
    "$$\n",
    "s(t) = \\int_{-\\infty}^{+\\infty}{x(a)w(t-a)da}\n",
    "$$\n",
    "\n",
    "$$\n",
    "s(t) = (x * w)(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "s(t) = \\sum_{a=-\\infty}^{\\infty}{x(a)w(t-a)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "S(i, j) = (I * K)(i,j) = \\sum_{m}\\sum_{n}{I(m,n) \\cdot K(i-m,j-n)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "S(i, j) = (K * I)(i,j) = \\sum_{m}\\sum_{n}{I(i-m, j-n) \\cdot K(m,n)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "S(i, j) = (K * I)(i,j) = \\sum_{m}\\sum_{n}{I(i+m, j+n) \\cdot K(m,n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "S(i, j) = (K * I)(i,j) = b + \\sum_{m}{\\sum_{n}{I(i+m, j+n) \\cdot K(m,n)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convnets\n",
    "\n",
    "Previously, we had to find filters (a.k.a. kernels) manually:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>![](FirstPixelMulitiplication.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./Convolution_schematic.gif)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "kernel = [0.0, 1.0, 0.0,\n",
    "          1.0, 0.0, 1.0,\n",
    "          0.0, 1.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5e61ac550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = Variable(torch.from_numpy(training[0][1])).unsqueeze(0).unsqueeze(0)\n",
    "vertical = nn.Conv2d(1, 1, 3, padding=1, bias=False)\n",
    "vertical.weight.data = torch.from_numpy(np.array(kernel, dtype=np.float32).reshape((1, 1, 3, 3)))\n",
    "output = vertical(inputs)\n",
    "showImage(output.data.numpy().reshape((28, 28)) / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convnets and DL\n",
    "\n",
    "let NN to learn its own filters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "Convnet \\rightarrow activation \\rightarrow pooling\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>![](./LeNet.png)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AlexNet\n",
    "![](./AlexNet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " * Trained the network on ImageNet data, which contained over 15 million annotated images from a total of over 22,000 categories.\n",
    " * Used ReLU for the nonlinearity functions (Found to decrease training time as ReLUs are several times faster than the conventional tanh function).\n",
    " * Used data augmentation techniques that consisted of image translations, horizontal reflections, and patch extractions.\n",
    " * Implemented dropout layers in order to combat the problem of overfitting to the training data.\n",
    " * Trained the model using batch stochastic gradient descent, with specific values for momentum and weight decay.\n",
    " * Trained on two GTX 580 GPUs for five to six days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./weights.jpeg)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GoogLeNet\n",
    "<center>![](./GoogLeNet.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inception\n",
    "<center>![](./GoogLeNet3.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### And deeper\n",
    " * ResNet (157 layers)\n",
    " * GANs\n",
    " * and many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>![](./Encoder7-1.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTM: Long Short Term Memory\n",
    "![](./LSTM3-chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Character level Language Model\n",
    "<center>![](./network.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FAIR seq\n",
    "\n",
    "<center>![](./fair.png)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bibliography and sources\n",
    "\n",
    " * [Course on Stanford](https://cs231n.github.io/convolutional-networks/)\n",
    " * [adeshpande3.github.io](https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    " * [UFLDL](http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/)\n",
    " * [Chapter on CNN in Deep Learning book](http://www.deeplearningbook.org/contents/convnets.html)\n",
    " * [AlexNet Paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### That's all for today!\n",
    "\n",
    "### Questions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
